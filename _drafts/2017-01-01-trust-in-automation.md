---
layout: post
title: Trust in Automation

---

*In which I discuss the problems with trusting machines to take our jobs, curate our news feeds, drive the school bus, teach our children, and other boring stuff too difficult to bother doing ourselves. Oh, and quotes. Lots of quotes.*

Houston, we have a problem. According to social media, a large fraction of our population will soon be unemployed. Not just unemployed, but [unemployable](https://www.youtube.com/watch?v=7Pq-S557XQU). Thanks to years of growth in the software industry and recent breakthroughs in automation and machine learning, a majority of the world's human labor will be economically obsolete. Too young to retire, and too old to retrain, there will be an enormous displacement of unskilled labor. This is not just idle speculation. Leading [scientists](https://twitter.com/AndrewYNg/status/815342695321174017) and [politicians](https://www.youtube.com/watch?v=72bHop6AIcc) have recognized the immediacy of this problem, and the importance of addressing it in our society.

Automation does not just affect unskilled laborers. Many jobs requiring advanced degrees and years of experience are vulnerable, including a large number of doctors, lawyers, architects and accountants. Each of these professions performs work which is already being learned, automated, and optimized by machines. Even [mathematical research](https://papers.nips.cc/paper/6280-deepmath-deep-sequence-models-for-premise-selection.pdf) at the boundaries of human understanding can be [automated](https://www.youtube.com/watch?v=qT8NyyRgLDQ). Today a growing number of mathematicians use [interactive proof assistants](https://en.wikipedia.org/wiki/Proof_assistant) and [automated theorem provers](https://en.wikipedia.org/wiki/Automated_theorem_proving) to verify their work, and even discover [new truths](https://en.wikipedia.org/wiki/Computer-assisted_proof#List_of_theorems_proved_with_the_help_of_computer_programs). But if [current events](https://en.wikipedia.org/wiki/Fake_news_websites_in_the_United_States) are any indication, what is true and what is verifiable are entirely [different matters](https://en.wikipedia.org/wiki/Wikipedia:Verifiability,_not_truth).

> And when your surpassing creations find the answers you asked for, you can't understand their analysis and you can't verify their answers. You have to take their word on faith—Or you use information theory to flatten it for you, to squash the tesseract into two dimensions and the Klein bottle into three, to simplify reality and pray to whatever Gods survived the millennium that your honorable twisting of the truth hasn't ruptured any of its load-bearing pylons. You hire people like me; the crossbred progeny of profilers and proof assistants and information theorists...
>
> In formal settings you'd call me Synthesist.
>
> —Blindsight (2006), Peter Watts

Peter Watts', in his breakout science-fiction novel, "Blindsight", imagines the possibility of professional "synthesists". In a future where most scientific breakthroughs are achieved by AI, synthesists, "explain the incomprehensible to the indifferent." Watts' protagonist, Siri Keaton is a spacefaring science officer who intercepts a [Matrioshka brain](https://en.wikipedia.org/wiki/Matrioshka_brain) outside the solar system. Siri is tasked with collecting observations and verifying the true nature of this strange object. But as Siri soon realizes, not all truths can be verified. Curiously, many science fiction writers have imagined a similar figure who helps bridge the gap between minds and machines.[ˆ1]

Science fiction authors tend to fall into three broad categories. The optimists dream of a post-scarcity utopia where technology descends like manna from AI heaven, and we all travel into some digital promised land, *en masse* as it were. The pessimists argue that robot overlords and evil mega-corporations will vie for control of a dystopian future where humans are mostly expendable. And the synergists suggest a hybrid future, where humans and machines co-exist in relative happiness, clinging to the hope we possess some vestigial importance to our metallic brethren. Such scenarios may seem improbable, or fantastic. But these thought experiments serve an important function as we grapple with the effects of increasing automation.

> People think—wrongly—that speculative fiction is about predicting the future… What speculative fiction is really good at is not the future but the present—taking an aspect of it that troubles or is dangerous, and extending and extrapolating that aspect into something that allows the people of that time to see what they are doing from a different angle and from a different place. It’s cautionary. —Neil Gaiman

Science fiction, or speculative fiction as some prefer, has a long history of anticipating current events, and takes lessons from past and present alike. In one remarkable passage of [The Three Body Problem](https://en.wikipedia.org/wiki/The_Three-Body_Problem), a man called Von Neumann helps an ancient Chinese emperor build a computer to predict the movements of stars across the sky. With the King's permission, he trains millions of soldiers to form logic gates and memory busses, instructing them to raise and lower flags and march around a vast plain. Wherever an error occurs, the emperor simply executes everyone involved and trains new replacements.

> Qin Shi Huang lifted the sword to the sky, and shouted: “Computer Formation!” Four giant bronze cauldrons at the corners of the platform came to life simultaneously with roaring flames. A group of soldiers standing on the sloping side of the pyramid facing the phalanx chanted in unison: “Computer Formation!”
>
> On the ground below, colors in the phalanx began to shift and move. Complicated and detailed circuit patterns appeared and gradually filled the entire formation. Ten minutes later, the army had made a thirty-six kilometer square computer motherboard...
>
> “This is really interesting,” Qin Shi Huang said, pointing to the spectacular sight. “Each individual’s behavior is so simple, yet together, they can produce such a complex, great whole! Europeans criticize me for my tyrannical rule, claiming that I suppress creativity. But in reality, a large number of men yoked by severe discipline can also produce great wisdom when bound together as one.”
>
> —The Three Body Problem, Cixin Liu

Cixin Liu is a sci-fi writer[ˆ2] in China, a country that stands to lose millions of jobs to automation. It is not difficult to see parallels between Liu's armies and the legions of migrant workers toiling in factories, building the machines that will soon replace them. And China is not the only country facing pressure from machines. Just as competing economies have faced competition from China, dozens of countries who depend on manufacturing are now threatened by the destabilizing presence of automation. As soon as you teach a robot to sew sweaters more cheaply than paying a human, suddenly every sweater-factory can run lights-out, 24/7, displacing thousands of workers overnight.

But job displacement, while a major challenge, is not the real problem facing our species. As history has shown, humanity has survived dozens of technological upheavals. In the agricultural revolution, nomadic hunter-gatherers started breeding their prey, growing their forage, wheeling their food into little villages. The industrial revolution enlisted those farmers as factory workers and foremen in village-sized machines that consumed raw materials and spat out smaller machines. Our ancestors saw vast social and economic change, and thrived in the process, despite their own share of contemporary detractors. *So what is the problem exactly?*

> For too many of us, it's become safer to retreat into our own bubbles, whether in our neighborhoods or on college campuses, or places of worship, or especially our social media feeds, surrounded by people who look like us and share the same political outlook and never challenge our assumptions. The rise of naked partisanship, and increasing economic and regional stratification, the splintering of our media into a channel for every taste — all this makes this great sorting seem natural, even inevitable. And increasingly, we become so secure in our bubbles that we start accepting only information, whether it's true or not, that fits our opinions, instead of basing our opinions on the evidence that is out there.
>
> —Farewell Address, Barack Obama

At the dawn of the information age, we were confident this new-fangled technology called the "internet" would be superior to old-fashioned forms of media consumption. The growth of social media would give voices to the voiceless and choices to the choiceless. It was a new media frontier with the ability to create and curate content according to your own tastes and interests. No longer was television the sole source of your daily dose of entertainment. Suddenly, you could read whatever you pleased and blog whenever you sneezed. Isn't it great? We can share new ideas and opinions with ease. Even your boss would agree, let's tweet and reshare this with him overseas!

The internet has ushered a great shift in modern society. Politicians and philosophers from ancient Rome could only dream of the meritocracy that instant access to unlimited information would one day grant to all humankind. What they could not foresee, is how that same technology would usher in a new kind of tyranny, one that would dwarf any government's use thereof. Instant access does not guarantee self-improvement, only the promise of easy gratification. Unlimited information does not reveal deeper truth, only an endless road of distractions. Without education, the internet is a tyranny of the mind. Without purpose, it is a prison.

> Then you will know the truth, and the truth will set you free.
>
> —John 8:32

*"A prison?"* you might say. *"Why, it's full of shiny gadgets, great entertainment, and people who agree with me. That doesn't sound so bad - I rather like it here!"* Those shiny gadgets are [Skinner boxes](https://en.wikipedia.org/wiki/Operant_conditioning_chamber). The entertainment? [Viral memes](https://en.wikipedia.org/wiki/Meme), waiting to infect your mind and eat your attention span. Those other people? Oh, they're just [reflections](https://en.wikipedia.org/wiki/Filter_bubble) who [echo our opinions](https://en.wikipedia.org/wiki/Echo_chamber_(media)), inflate our egos, and [confirm our biases](https://en.wikipedia.org/wiki/Confirmation_bias). The prison wardens are very good at giving us exactly what we want. The best part is we don't even need to ask, they can practically read our minds.

All this sounds rather dire, and perhaps it is a bit of hyperbole. Like my schoolteacher used to say, "Don't trust anything you read on the internet." The internet provides opportunity and oppression, education and entertainment, truth and fiction, all in equal measure. *The real problem is, one of these things looks exactly like the other.* How is a color-blind chap in the Matrix supposed to know [which pill](https://en.wikipedia.org/wiki/Red_pill_and_blue_pill) to swallow? Should we take Morpheus at his word? As it happens, when dealing with black boxes that can read your mind, the problem of the internet becomes surprisingly more difficult.

> If our brains were simple enough for us to understand them, we'd be so simple that we couldn't.
>
> ―Ian Stewart, The Collapse of Chaos

Machine learning researchers have poured millions of dollars into something called [explainable AIs](http://www.darpa.mil/program/explainable-artificial-intelligence). As far as we can tell, they're not explainable. Sure, we know how to build them using GPUs and gigabytes of data. We use fancy words like backpropogation, gradient-descent, convolutions, and hyperparameters. We can poke and prod them, try a zillion different settings and sometimes they become more accurate. But why do they classify you as a criminal and me as an upstanding citizen? Because your face looks kinda criminal...ly?

Apparently, automated criminality inference based on facial images is now a [real thing](https://arxiv.org/abs/1611.04135) for Chinese people. But there are many flaws which exist in the design and testing of this model, and the underlying assumptions. Even if AIs can explain their decision logic, the problem is not the algorithms themselves, but the kinds of people who are willing to apply them, regardless of whether they understand the math underneath. If some algorithm is 30% confident you're a terrorist based a list of suspicious IP addresses that visit your blog, security sure isn't going to debug the program that says you can't board that plane.

> "There are three kinds of lies: lies, damned lies, and statistics."
>
> ―[Mark Twain or someone](https://en.wikipedia.org/wiki/Lies,_damned_lies,_and_statistics)

One of the major limitations of user interfaces is bandwidth - keyboards and screens can only exchange so much information with their users. But today's computers have the ability to interact with their environment in exciting new ways. From self-flying drones to virtual patients, and home appliances to smart assistants, machines are becoming increasingly perceptive, and increasingly conversant. Machines can see, hear, and understand natural language. They can recognize faces and speech, anticipate intentions and assist with increasingly sophisticated tasks. We call these capabilities "artificial intelligence". But a more apt name might be "[augmented intelligence](https://en.wikipedia.org/wiki/Intelligence_amplification)".

### Citations

[ˆ1]: Pavel Chekov
[ˆ2]: Arguably the most famous sci-fi writer in China.